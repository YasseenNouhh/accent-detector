#!/usr/bin/env python3
"""
Test script for the new Wav2Vec2 accent classification models
This script tests if the accent detection models are working correctly
"""

import sys
import os
import numpy as np
import librosa
from pathlib import Path

def test_accent_models():
    """Test the accent classification models"""
    print("=== TESTING ACCENT CLASSIFICATION MODELS ===\n")
    
    # Test 1: Check if transformers library is available
    print("1. Testing transformers library...")
    try:
        from transformers import pipeline
        print("âœ… transformers library imported successfully")
    except ImportError as e:
        print(f"âŒ transformers library not available: {e}")
        return False
    
    # Test 2: Check if torch is available
    print("\n2. Testing PyTorch...")
    try:
        import torch
        print(f"âœ… PyTorch available: {torch.__version__}")
        print(f"   CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDA device: {torch.cuda.get_device_name()}")
    except ImportError as e:
        print(f"âŒ PyTorch not available: {e}")
        return False
    
    # Test 3: Check if audio processing libraries are available
    print("\n3. Testing audio processing libraries...")
    try:
        import librosa
        import soundfile
        print("âœ… Audio processing libraries available")
    except ImportError as e:
        print(f"âŒ Audio processing libraries not available: {e}")
        return False
    
    # Test 4: Create a synthetic audio sample for testing
    print("\n4. Creating synthetic audio sample...")
    try:
        # Generate a simple sine wave as test audio
        duration = 5  # seconds
        sample_rate = 16000
        frequency = 440  # A4 note
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio = np.sin(2 * np.pi * frequency * t) * 0.3
        print(f"âœ… Created synthetic audio: {duration}s at {sample_rate}Hz")
    except Exception as e:
        print(f"âŒ Failed to create synthetic audio: {e}")
        return False
    
    # Test 5: Test ylacombe/accent-classifier
    print("\n5. Testing ylacombe/accent-classifier...")
    try:
        accent_classifier = pipeline(
            "audio-classification", 
            model="ylacombe/accent-classifier",
            device=0 if torch.cuda.is_available() else -1
        )
        
        # Test with synthetic audio
        predictions = accent_classifier(audio)
        print("âœ… ylacombe/accent-classifier working!")
        print(f"   Top prediction: {predictions[0]['label']} ({predictions[0]['score']:.3f})")
        
    except Exception as e:
        print(f"âš ï¸ ylacombe/accent-classifier failed: {e}")
        print("   This is expected if the model is not available online")
    
    # Test 6: Test dima806/multiple_accent_classification
    print("\n6. Testing dima806/multiple_accent_classification...")
    try:
        accent_classifier = pipeline(
            "audio-classification", 
            model="dima806/multiple_accent_classification",
            device=0 if torch.cuda.is_available() else -1
        )
        
        predictions = accent_classifier(audio)
        print("âœ… dima806/multiple_accent_classification working!")
        print(f"   Top prediction: {predictions[0]['label']} ({predictions[0]['score']:.3f})")
        
    except Exception as e:
        print(f"âš ï¸ dima806/multiple_accent_classification failed: {e}")
        print("   This is expected if the model is not available online")
    
    # Test 7: Test custom Wav2Vec2 feature extraction
    print("\n7. Testing custom Wav2Vec2 feature extraction...")
    try:
        from transformers import Wav2Vec2Processor, Wav2Vec2Model
        
        model_name = "facebook/wav2vec2-base"
        processor = Wav2Vec2Processor.from_pretrained(model_name)
        wav2vec2_model = Wav2Vec2Model.from_pretrained(model_name)
        
        # Process audio
        inputs = processor(audio, sampling_rate=sample_rate, return_tensors="pt", padding=True)
        
        with torch.no_grad():
            outputs = wav2vec2_model(**inputs)
            hidden_states = outputs.last_hidden_state
            pooled_features = torch.mean(hidden_states, dim=1)
            features = pooled_features.squeeze().numpy()
        
        print("âœ… Custom Wav2Vec2 feature extraction working!")
        print(f"   Feature dimensions: {len(features)}")
        print(f"   Feature stats: mean={np.mean(features):.4f}, std={np.std(features):.4f}")
        
    except Exception as e:
        print(f"âŒ Custom Wav2Vec2 feature extraction failed: {e}")
        return False
    
    # Test 8: Test accent mapping
    print("\n8. Testing accent name normalization...")
    accent_mapping = {
        'british': 'British (RP)',
        'american': 'American',
        'australian': 'Australian',
        'canadian': 'Canadian',
        'irish': 'Irish',
        'scottish': 'Scottish',
        'south_african': 'South African',
        'indian': 'Indian',
        'us': 'American',
        'uk': 'British (RP)',
        'au': 'Australian',
        'ca': 'Canadian',
        'ie': 'Irish',
        'scotland': 'Scottish',
        'za': 'South African'
    }
    
    test_accents = ['british', 'us', 'au', 'unknown_accent']
    for accent in test_accents:
        normalized = accent_mapping.get(accent.lower(), accent)
        print(f"   {accent} -> {normalized}")
    
    print("âœ… Accent name normalization working!")
    
    print("\n=== TEST SUMMARY ===")
    print("âœ… Core libraries available")
    print("âœ… Audio processing working")
    print("âœ… Wav2Vec2 feature extraction working")
    print("âš ï¸ Online models may not be available (expected in offline environments)")
    print("âœ… Fallback system will work if online models fail")
    
    return True

def test_with_real_audio():
    """Test with a real audio file if available"""
    print("\n=== TESTING WITH REAL AUDIO ===")
    
    # Look for audio files in common directories
    audio_dirs = ['audio', 'test_audio', '.']
    audio_extensions = ['.wav', '.mp3', '.m4a', '.flac']
    
    test_file = None
    for audio_dir in audio_dirs:
        if os.path.exists(audio_dir):
            for file in os.listdir(audio_dir):
                if any(file.lower().endswith(ext) for ext in audio_extensions):
                    test_file = os.path.join(audio_dir, file)
                    break
            if test_file:
                break
    
    if test_file:
        print(f"Found test audio file: {test_file}")
        try:
            # Load the audio file
            audio, sr = librosa.load(test_file, sr=16000, mono=True)
            duration = len(audio) / sr
            print(f"âœ… Loaded audio: {duration:.1f}s at {sr}Hz")
            
            # Test feature extraction
            from transformers import Wav2Vec2Processor, Wav2Vec2Model
            import torch
            
            model_name = "facebook/wav2vec2-base"
            processor = Wav2Vec2Processor.from_pretrained(model_name)
            wav2vec2_model = Wav2Vec2Model.from_pretrained(model_name)
            
            # Truncate if too long
            max_length = 30 * sr
            if len(audio) > max_length:
                audio = audio[:max_length]
            
            inputs = processor(audio, sampling_rate=sr, return_tensors="pt", padding=True)
            
            with torch.no_grad():
                outputs = wav2vec2_model(**inputs)
                hidden_states = outputs.last_hidden_state
                pooled_features = torch.mean(hidden_states, dim=1)
                features = pooled_features.squeeze().numpy()
            
            print(f"âœ… Real audio feature extraction successful!")
            print(f"   Feature dimensions: {len(features)}")
            print(f"   Feature stats: mean={np.mean(features):.4f}, std={np.std(features):.4f}")
            
        except Exception as e:
            print(f"âŒ Real audio test failed: {e}")
    else:
        print("No test audio files found. Skipping real audio test.")

if __name__ == "__main__":
    print("Accent Classification Model Test")
    print("=" * 50)
    
    success = test_accent_models()
    
    if success:
        test_with_real_audio()
        print("\nğŸ‰ All tests completed! The accent detection system should work correctly.")
        print("ğŸ’¡ Note: Online models may not be available in all environments.")
        print("ğŸ”„ The system will automatically fall back to rule-based detection if needed.")
    else:
        print("\nâŒ Some tests failed. Please check your environment setup.")
        sys.exit(1) 